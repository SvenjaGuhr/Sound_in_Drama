{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f09a84fe-f503-4f4b-ab03-f201907145c3",
   "metadata": {},
   "source": [
    "# Stage Direction Modifier for XML Plays\n",
    "\n",
    "This notebook processes XML files containing plays to modify the `<stage>` elements based on the speaker and context. The goal is to ensure that each stage direction is appropriately annotated with the verb indicating speech, such as \"sagt\" (for singular speakers) or \"sagen\" (for plural speakers), based on the surrounding context.\n",
    "\n",
    "### Key Features:\n",
    "1. **Finite Verb Detection**: The script detects finite verbs within the `<stage>` direction using spaCy's part-of-speech (POS) tagging.\n",
    "2. **Verb Insertion**: If a stage direction lacks a speech verb, the script adds \"sagt\" or \"sagen\" at the beginning. If a stage direction contains multiple finite verbs, \"und\" is inserted between them, ensuring correct syntax.\n",
    "3. **Plurality Handling**: The script checks if the speaker is plural (based on the `who` attribute) and adjusts the verb to \"sagen\" when needed.\n",
    "4. **Proper Sentence Handling**: The algorithm avoids modifying stage directions that already start with uppercase letters (typically indicating proper sentences).\n",
    "\n",
    "### How it Works:\n",
    "- The script iterates over each `<sp>` element in the XML file, checks for the presence of `<stage>` and `<p>`, and processes the stage direction accordingly.\n",
    "- It ensures that the speech act verb (\"sagt\" or \"sagen\") is added at the correct position, with proper handling of commas and multiple verbs.\n",
    "\n",
    "This notebook helps automate the process of transforming and annotating stage directions in narrative plays, making them more suitable for further linguistic processing or analysis.\n",
    "\n",
    "### Requirements:\n",
    "- **spaCy**: For part-of-speech tagging and verb detection.\n",
    "- **lxml**: For XML parsing and manipulation.\n",
    "\n",
    "Make sure to install the necessary dependencies before running the notebook:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38db9d6-6dc6-4a29-91e2-234c03794855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bash\n",
    "#!pip install spacy lxml\n",
    "#!python -m spacy download de_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96dec86f-322c-4723-9c63-f31eace190bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load spaCy German model\n",
    "nlp = spacy.load(\"de_core_news_md\")  # or \"de_core_news_lg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f209a43d-dea3-4e49-8d35-48d854143b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_folder(input_dir, output_dir):\n",
    "    \"\"\"\n",
    "    Process a folder of XML files, modifying the stage elements based on the logic.\n",
    "    \"\"\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    for filename in os.listdir(input_dir):\n",
    "        if filename.endswith(\".xml\"):\n",
    "            file_path = os.path.join(input_dir, filename)\n",
    "            try:\n",
    "                tree = ET.parse(file_path)\n",
    "                strip_namespace(tree)\n",
    "                modify_stage_elements(tree)\n",
    "\n",
    "                output_path = os.path.join(output_dir, filename)\n",
    "                tree.write(output_path, encoding='utf-8', xml_declaration=True)\n",
    "                print(f\"Processed: {filename}\")\n",
    "            except ET.ParseError as e:\n",
    "                print(f\"Error parsing {filename}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b1c856f-4dc3-4541-805d-f4d9128388b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Helper functions to check POS tags\n",
    "\n",
    "def is_action_like(text):\n",
    "    \"\"\"\n",
    "    Check if the stage direction starts with an action verb (finite verb).\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    if not doc:\n",
    "        return False\n",
    "\n",
    "    # Heuristic: starts with a verb + possibly a pronoun (reflexive verb like 'küßt ihn')\n",
    "    if len(doc) > 1 and doc[0].pos_ == \"VERB\":\n",
    "        if doc[1].pos_ in {\"PRON\", \"DET\"}:\n",
    "            return True\n",
    "    return doc[0].pos_ == \"VERB\"\n",
    "\n",
    "def is_tone_modifier(text):\n",
    "    \"\"\"\n",
    "    Check if the stage direction starts with a tone modifier (adjective or adverb).\n",
    "    \"\"\"\n",
    "    doc = nlp(text)\n",
    "    if not doc:\n",
    "        return False\n",
    "    return doc[0].pos_ in {\"ADJ\", \"ADV\"}  # e.g., \"leise\", \"ekstatisch\"\n",
    "\n",
    "def is_plural_speaker(sp_element):\n",
    "    \"\"\"\n",
    "    Heuristic to check if the speaker refers to multiple characters (plural).\n",
    "    \"\"\"\n",
    "    who = sp_element.attrib.get('who', '')\n",
    "    return len(who.strip().split()) > 1  # multiple IDs means plural\n",
    "\n",
    "def strip_namespace(tree):\n",
    "    \"\"\"\n",
    "    Strip XML namespaces to make processing easier.\n",
    "    \"\"\"\n",
    "    for elem in tree.iter():\n",
    "        if '}' in elem.tag:\n",
    "            elem.tag = elem.tag.split('}', 1)[1]\n",
    "    return tree\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07bf8474-9d06-448f-9052-9b9d8d77c8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#works great as generalization \n",
    "\n",
    "def is_finite_verb(token):\n",
    "    \"\"\"\n",
    "    Check if the token is a finite verb.\n",
    "    \"\"\"\n",
    "    return token.pos_ == 'VERB' and token.tag_ in ['VVFIN', 'VAFIN']\n",
    "\n",
    "def is_plural_speaker(sp):\n",
    "    \"\"\"\n",
    "    Check if the speaker is plural by looking at the 'who' attribute.\n",
    "    \"\"\"\n",
    "    return len(sp.attrib.get('who', '').split()) > 1\n",
    "\n",
    "def modify_stage_elements(tree):\n",
    "    \"\"\"\n",
    "    Modify the <stage> elements based on the POS-tagging logic.\n",
    "    \"\"\"\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for sp in root.iter('sp'):\n",
    "        # Attempt to get the <stage> and <p> elements safely\n",
    "        stage = sp.find('stage')\n",
    "        paragraph = sp.find('p')\n",
    "\n",
    "        # Skip if the stage element is missing or has no text content\n",
    "        if stage is None or stage.text is None or not stage.text.strip():\n",
    "            #print(f\"Warning: Missing or empty <stage> in <sp> with speaker {sp.find('speaker').text if sp.find('speaker') else 'Unknown'}\")\n",
    "            continue  # Skip to the next <sp> if there's no stage element\n",
    "\n",
    "        # Skip if the paragraph <p> is missing or has no text content\n",
    "        if paragraph is None or paragraph.text is None or not paragraph.text.strip():\n",
    "            #print(f\"Warning: Missing or empty <p> in <sp> with speaker {sp.find('speaker').text if sp.find('speaker') else 'Unknown'}\")\n",
    "            continue  # Skip to the next <sp> if there's no paragraph element or it's empty\n",
    "\n",
    "        # Safe processing of <stage> content after confirming it exists\n",
    "        original = stage.text.strip()\n",
    "\n",
    "        # Skip the stage direction if it starts with an uppercase letter (likely already a proper sentence)\n",
    "        if original[0].isupper():\n",
    "            continue  # Skip further processing if stage direction starts with uppercase\n",
    "\n",
    "        # Remove trailing punctuation like '.' or '!' to make processing easier\n",
    "        content = original.rstrip('.!?').strip()\n",
    "\n",
    "        # Parse the stage direction text with spaCy to check for multiple verbs\n",
    "        doc = nlp(content)\n",
    "        verbs = [token for token in doc if is_finite_verb(token)]\n",
    "\n",
    "        # If no finite verb is found, we will add \"sagt\" by default\n",
    "        if not verbs:\n",
    "            verb = \"sagen\" if is_plural_speaker(sp) else \"sagt\"\n",
    "            stage.text = f\"{verb} {content}.\"\n",
    "        else:\n",
    "            # Handle the case where we already have a finite verb\n",
    "            if len(verbs) == 1:\n",
    "                # Add \"sagt\" or \"sagen\" and connect it with \"und\" to the other finite verbs\n",
    "                verb = \"sagen\" if is_plural_speaker(sp) else \"sagt\"\n",
    "                stage.text = f\"{verb} und {content}\"\n",
    "            elif len(verbs) > 1:\n",
    "                # Multiple verbs, so add \"und\" between them but only after \"sagt\" or \"sagen\"\n",
    "                verbs_str = \" und \".join([token.text for token in verbs])\n",
    "                remaining_content = \" \".join([token.text for token in doc if token not in verbs])\n",
    "                stage.text = f\"{verbs_str} {remaining_content}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5714eb42-847e-4631-a757-43ccb0adb6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed: wedekind-fruehlings-erwachen.xml\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "input_directory = \"/Users/sguhr/Desktop/Arbeitslaptop/TU_Darmstadt/2024:25/CLS_Kurzstipendium/Sound_in_Drama\"\n",
    "output_directory = \"/Users/sguhr/Desktop/Arbeitslaptop/TU_Darmstadt/2024:25/CLS_Kurzstipendium/Sound_in_Drama/manipulated_texts_generalized_approach\"\n",
    "\n",
    "process_folder(input_directory, output_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02223d7f-b401-46dd-a470-7b230baf667c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
